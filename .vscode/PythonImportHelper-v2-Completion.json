[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "coremltools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "coremltools",
        "description": "coremltools",
        "detail": "coremltools",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "LinearQuantizer",
        "importPath": "coremltools.optimize.torch.quantization",
        "description": "coremltools.optimize.torch.quantization",
        "isExtraImport": true,
        "detail": "coremltools.optimize.torch.quantization",
        "documentation": {}
    },
    {
        "label": "LinearQuantizerConfig",
        "importPath": "coremltools.optimize.torch.quantization",
        "description": "coremltools.optimize.torch.quantization",
        "isExtraImport": true,
        "detail": "coremltools.optimize.torch.quantization",
        "documentation": {}
    },
    {
        "label": "ModuleLinearQuantizerConfig",
        "importPath": "coremltools.optimize.torch.quantization",
        "description": "coremltools.optimize.torch.quantization",
        "isExtraImport": true,
        "detail": "coremltools.optimize.torch.quantization",
        "documentation": {}
    },
    {
        "label": "StableDiffusionPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "ModelMixin",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "StableDiffusionPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "StableDiffusionXLPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "StableDiffusionPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "DiffusionPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "ControlNetModel",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "ModelMixin",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "StableDiffusionPipeline",
        "importPath": "diffusers",
        "description": "diffusers",
        "isExtraImport": true,
        "detail": "diffusers",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "attention",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "unet",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "torch2coreml",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "unet",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "controlnet",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "chunk_mlprogram",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "attention",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "torch2coreml",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "coreml_model",
        "importPath": "python_coreml_stable_diffusion",
        "description": "python_coreml_stable_diffusion",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "LayerNormANE",
        "importPath": "python_coreml_stable_diffusion.layer_norm",
        "description": "python_coreml_stable_diffusion.layer_norm",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.layer_norm",
        "documentation": {}
    },
    {
        "label": "LayerNormANE",
        "importPath": "python_coreml_stable_diffusion.layer_norm",
        "description": "python_coreml_stable_diffusion.layer_norm",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.layer_norm",
        "documentation": {}
    },
    {
        "label": "compute_psnr",
        "importPath": "python_coreml_stable_diffusion.torch2coreml",
        "description": "python_coreml_stable_diffusion.torch2coreml",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "get_pipeline",
        "importPath": "python_coreml_stable_diffusion.torch2coreml",
        "description": "python_coreml_stable_diffusion.torch2coreml",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "compute_psnr",
        "importPath": "python_coreml_stable_diffusion.torch2coreml",
        "description": "python_coreml_stable_diffusion.torch2coreml",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "get_pipeline",
        "importPath": "python_coreml_stable_diffusion.torch2coreml",
        "description": "python_coreml_stable_diffusion.torch2coreml",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "_compile_coreml_model",
        "importPath": "python_coreml_stable_diffusion.torch2coreml",
        "description": "python_coreml_stable_diffusion.torch2coreml",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "Einsum",
        "importPath": "python_coreml_stable_diffusion.unet",
        "description": "python_coreml_stable_diffusion.unet",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Block",
        "importPath": "coremltools.converters.mil",
        "description": "coremltools.converters.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil",
        "documentation": {}
    },
    {
        "label": "Program",
        "importPath": "coremltools.converters.mil",
        "description": "coremltools.converters.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil",
        "documentation": {}
    },
    {
        "label": "Var",
        "importPath": "coremltools.converters.mil",
        "description": "coremltools.converters.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "coremltools.converters.mil.frontend.milproto.load",
        "description": "coremltools.converters.mil.frontend.milproto.load",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.frontend.milproto.load",
        "documentation": {}
    },
    {
        "label": "Builder",
        "importPath": "coremltools.converters.mil.mil",
        "description": "coremltools.converters.mil.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil",
        "documentation": {}
    },
    {
        "label": "Placeholder",
        "importPath": "coremltools.converters.mil.mil",
        "description": "coremltools.converters.mil.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "coremltools.converters.mil.mil",
        "description": "coremltools.converters.mil.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "coremltools.converters.mil.mil",
        "description": "coremltools.converters.mil.mil",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil",
        "documentation": {}
    },
    {
        "label": "block_context_manager",
        "importPath": "coremltools.converters.mil.mil.passes.helper",
        "description": "coremltools.converters.mil.mil.passes.helper",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil.passes.helper",
        "documentation": {}
    },
    {
        "label": "PASS_REGISTRY",
        "importPath": "coremltools.converters.mil.mil.passes.pass_registry",
        "description": "coremltools.converters.mil.mil.passes.pass_registry",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.mil.passes.pass_registry",
        "documentation": {}
    },
    {
        "label": "random_gen_input_feature_type",
        "importPath": "coremltools.converters.mil.testing_utils",
        "description": "coremltools.converters.mil.testing_utils",
        "isExtraImport": true,
        "detail": "coremltools.converters.mil.testing_utils",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "ConfigMixin",
        "importPath": "diffusers.configuration_utils",
        "description": "diffusers.configuration_utils",
        "isExtraImport": true,
        "detail": "diffusers.configuration_utils",
        "documentation": {}
    },
    {
        "label": "register_to_config",
        "importPath": "diffusers.configuration_utils",
        "description": "diffusers.configuration_utils",
        "isExtraImport": true,
        "detail": "diffusers.configuration_utils",
        "documentation": {}
    },
    {
        "label": "ConfigMixin",
        "importPath": "diffusers.configuration_utils",
        "description": "diffusers.configuration_utils",
        "isExtraImport": true,
        "detail": "diffusers.configuration_utils",
        "documentation": {}
    },
    {
        "label": "register_to_config",
        "importPath": "diffusers.configuration_utils",
        "description": "diffusers.configuration_utils",
        "isExtraImport": true,
        "detail": "diffusers.configuration_utils",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "coremltools.optimize.coreml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "coremltools.optimize.coreml",
        "description": "coremltools.optimize.coreml",
        "detail": "coremltools.optimize.coreml",
        "documentation": {}
    },
    {
        "label": "NBITS",
        "importPath": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "PALETTIZE_MIN_SIZE",
        "importPath": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "DiffusionPipeline",
        "importPath": "diffusers.pipelines.pipeline_utils",
        "description": "diffusers.pipelines.pipeline_utils",
        "isExtraImport": true,
        "detail": "diffusers.pipelines.pipeline_utils",
        "documentation": {}
    },
    {
        "label": "StableDiffusionPipelineOutput",
        "importPath": "diffusers.pipelines.stable_diffusion",
        "description": "diffusers.pipelines.stable_diffusion",
        "isExtraImport": true,
        "detail": "diffusers.pipelines.stable_diffusion",
        "documentation": {}
    },
    {
        "label": "DDIMScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "DPMSolverMultistepScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "EulerAncestralDiscreteScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "EulerDiscreteScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "LMSDiscreteScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "PNDMScheduler",
        "importPath": "diffusers.schedulers",
        "description": "diffusers.schedulers",
        "isExtraImport": true,
        "detail": "diffusers.schedulers",
        "documentation": {}
    },
    {
        "label": "SchedulerMixin",
        "importPath": "diffusers.schedulers.scheduling_utils",
        "description": "diffusers.schedulers.scheduling_utils",
        "isExtraImport": true,
        "detail": "diffusers.schedulers.scheduling_utils",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "CoreMLModel",
        "importPath": "python_coreml_stable_diffusion.coreml_model",
        "description": "python_coreml_stable_diffusion.coreml_model",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "_load_mlpackage",
        "importPath": "python_coreml_stable_diffusion.coreml_model",
        "description": "python_coreml_stable_diffusion.coreml_model",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "_load_mlpackage_controlnet",
        "importPath": "python_coreml_stable_diffusion.coreml_model",
        "description": "python_coreml_stable_diffusion.coreml_model",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "get_available_compute_units",
        "importPath": "python_coreml_stable_diffusion.coreml_model",
        "description": "python_coreml_stable_diffusion.coreml_model",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "CLIPFeatureExtractor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "convert_mmdit_to_mlpackage",
        "importPath": "diffusionkit.tests.torch2coreml",
        "description": "diffusionkit.tests.torch2coreml",
        "isExtraImport": true,
        "detail": "diffusionkit.tests.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_vae_to_mlpackage",
        "importPath": "diffusionkit.tests.torch2coreml",
        "description": "diffusionkit.tests.torch2coreml",
        "isExtraImport": true,
        "detail": "diffusionkit.tests.torch2coreml",
        "documentation": {}
    },
    {
        "label": "snapshot_download",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "MethodType",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "modeling_clip",
        "importPath": "transformers.models.clip",
        "description": "transformers.models.clip",
        "isExtraImport": true,
        "detail": "transformers.models.clip",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "_macos_version",
        "importPath": "coremltools.models.utils",
        "description": "coremltools.models.utils",
        "isExtraImport": true,
        "detail": "coremltools.models.utils",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "median",
        "importPath": "statistics",
        "description": "statistics",
        "isExtraImport": true,
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "python_coreml_stable_diffusion._version",
        "description": "python_coreml_stable_diffusion._version",
        "isExtraImport": true,
        "detail": "python_coreml_stable_diffusion._version",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "ImageForge.node_modules.flatted.python.flatted",
        "description": "ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "ImageForge.node_modules.flatted.python.flatted",
        "description": "ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "ImageForge.node_modules.flatted.python.flatted",
        "description": "ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "ImageForge.node_modules.flatted.python.flatted",
        "description": "ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "ios.ImageForge.node_modules.flatted.python.flatted",
        "description": "ios.ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "ios.ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "ios.ImageForge.node_modules.flatted.python.flatted",
        "description": "ios.ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "ios.ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "ios.ImageForge.node_modules.flatted.python.flatted",
        "description": "ios.ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "ios.ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "ios.ImageForge.node_modules.flatted.python.flatted",
        "description": "ios.ImageForge.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "ios.ImageForge.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion._version",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion._version",
        "peekOfCode": "__version__ = \"1.1.0\"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion._version",
        "documentation": {}
    },
    {
        "label": "get_coreml_inputs",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def get_coreml_inputs(sample_inputs):\n    return [\n        ct.TensorType(\n            name=k,\n            shape=v.shape,\n            dtype=v.numpy().dtype if isinstance(v, torch.Tensor) else v.dtype,\n        ) for k, v in sample_inputs.items()\n    ]\ndef convert_to_coreml(torchscript_module, sample_inputs):\n    logger.info(\"Converting model to CoreML..\")",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "convert_to_coreml",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def convert_to_coreml(torchscript_module, sample_inputs):\n    logger.info(\"Converting model to CoreML..\")\n    coreml_model = ct.convert(\n        torchscript_module,\n        convert_to=\"mlprogram\",\n        minimum_deployment_target=ct.target.macOS14,\n        inputs=get_coreml_inputs(sample_inputs),\n        outputs=[ct.TensorType(name=\"noise_pred\", dtype=np.float32)],\n        compute_units=ct.ComputeUnit.ALL,\n        skip_model_load=True,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "unet_data_loader",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def unet_data_loader(data_dir, device='cpu', calibration_nsamples=None):\n    \"\"\"\n    Load calibration data from specified path.\n    Limit number of samples to calibration_nsamples, if specified.\n    \"\"\"\n    dataloader = []\n    skip_load = False\n    for file in sorted(os.listdir(data_dir)):\n        if file.endswith('.pkl'):\n            filepath = os.path.join(data_dir, file)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "quantize_module_config",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def quantize_module_config(module_name):\n    \"\"\"\n    Generate quantization config to apply W8A8 quantization for specified module.\n    Rest of the model is kept in FP32 precision.\n    \"\"\"\n    config = LinearQuantizerConfig(\n        global_config=ModuleLinearQuantizerConfig(\n            milestones=[0, 1000, 1000, 0],\n            weight_dtype=torch.float32,\n            activation_dtype=torch.float32,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "quantize_cumulative_config",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def quantize_cumulative_config(skip_conv_layers, skip_einsum_layers):\n    \"\"\"\n    Generate quantization config to apply W8A8 quantization.\n    Skipped layers are kept in W8A32 precision.\n    \"\"\"\n    logger.info(f\"Skipping {len(skip_conv_layers)} conv layers and {len(skip_einsum_layers)} einsum layers\")\n    w8config = ModuleLinearQuantizerConfig(\n            quantization_scheme=\"symmetric\",\n            milestones=[0, 1000, 1000, 0],\n            activation_dtype=torch.float32)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "quantize",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def quantize(model, config, calibration_data):\n    \"\"\"\n    Apply post training activation quantization to specified model, using calibration data\n    \"\"\"\n    submodules = dict(model.named_modules(remove_duplicate=True))\n    layer_norm_modules = [key for key, val in submodules.items() if isinstance(val, LayerNormANE)]\n    non_traceable_module_names = layer_norm_modules + [\n        \"time_proj\",\n        \"time_embedding\",\n    ]",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "get_quantizable_modules",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def get_quantizable_modules(unet):\n    quantizable_modules = []\n    for name, module in unet.named_modules():\n        if len(list(module.children())) > 0:\n            continue\n        if type(module) == torch.nn.modules.conv.Conv2d:\n            quantizable_modules.append(('conv', name))\n        if type(module) == Einsum:\n            quantizable_modules.append(('einsum', name))\n    return quantizable_modules",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "recipe_overrides_for_inference_speedup",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def recipe_overrides_for_inference_speedup(conv_layers, skipped_conv):\n    \"\"\"\n    Quantize the slowest conv layers, even if in skipped set based on PSNR, for good inference speedup\n    \"\"\"\n    for layer in conv_layers:\n        if \"up_blocks\" in layer and \"resnets\" in layer and \"conv1\" in layer:\n            if layer in skipped_conv:\n                logger.info(f\"removing {layer}\")\n                skipped_conv.remove(layer)\n        if \"upsamplers\" in layer:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "recipe_overrides_for_quality",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def recipe_overrides_for_quality(conv_layers, skipped_conv):\n    \"\"\"\n    Do not quantize out projection layers to avoid quantizing outputs of preceding concat layers.\n    Quantizing output of concat layers can lead to quality degradation, due to sharing of scales\n    across concat inputs, which can have varied ranges. Since this is a constraint enforced during\n    model conversion, it may not be captured in layer-wise PSNR analysis of PyTorch model.\n    \"\"\"\n    out_proj_layers = [layer for layer in conv_layers if \"to_out\" in layer]\n    for layer in out_proj_layers:\n        if layer not in skipped_conv:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "register_input_log_hook",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def register_input_log_hook(unet, inputs):\n    \"\"\"\n    Register forward pre hook to save model inputs \n    \"\"\"\n    def hook(_, input):\n        input_copy = deepcopy(input)\n        input_copy = tuple(i.to('cpu') for i in input_copy)\n        inputs.append(input_copy)\n        # Return inputs unmodified\n        return input",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "generate_calibration_data",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def generate_calibration_data(pipe, args, calibration_dir):\n    # Register forward pre hook to record unet inputs\n    unet_inputs = []\n    handle = register_input_log_hook(pipe.unet, unet_inputs)\n    # If directory doesn't exist, create it\n    os.makedirs(calibration_dir, exist_ok=True)\n    # Run calibration prompts through the pipeline and\n    # serialize recorded UNet model inputs\n    for prompt in CALIBRATION_DATA:\n        gen = torch.manual_seed(args.seed)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "register_input_preprocessing_hook",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def register_input_preprocessing_hook(pipe):\n    \"\"\"\n    Register forward pre hook to convert UNet inputs from HuggingFace StableDiffusionPipeline\n    to match expected model inputs in UNet2DConditionModel defined in unet.py\n    \"\"\"\n    def hook(_, args, kwargs):\n        sample = args[0]\n        timestep = args[1]\n        if len(timestep.shape) == 0:\n            timestep = timestep[None]",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "prepare_pipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def prepare_pipe(pipe, unet):\n    \"\"\"\n    Create a new pipeline from `pipe` with `unet` as the noise predictor\n    \"\"\"\n    new_pipe = deepcopy(pipe)\n    unet.to(new_pipe.unet.device)\n    new_pipe.unet = unet\n    pre_hook_handle = register_input_preprocessing_hook(new_pipe)\n    return new_pipe, pre_hook_handle\ndef run_pipe(pipe):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "run_pipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def run_pipe(pipe):\n    gen = torch.manual_seed(args.seed)\n    kwargs = dict(\n        prompt=RANDOM_TEST_DATA,\n        output_type=\"latent\",\n        generator=gen,\n    )\n    return np.array([latent.cpu().numpy() for latent in pipe(**kwargs).images])\ndef get_reference_pipeline(model_version):\n    # Initialize pipe",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "get_reference_pipeline",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def get_reference_pipeline(model_version):\n    # Initialize pipe\n    pipe = StableDiffusionPipeline.from_pretrained(\n        model_version,\n        use_safetensors=True,\n        use_auth_token=True,\n    )\n    DEFAULT_NUM_INFERENCE_STEPS = 50\n    pipe.scheduler.set_timesteps(DEFAULT_NUM_INFERENCE_STEPS)\n    # Initialize reference unet",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "def main(args):\n    # Initialize reference pipeline\n    ref_pipe = get_reference_pipeline(args.model_version)\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    logger.debug(f\"Placing pipe in {device}\")\n    ref_pipe.to(device)\n    # Generate baseline outputs",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "logger = logging.getLogger()\nlogger.setLevel('INFO')\nimport argparse\nimport gc\nimport json\nimport os\nimport pickle\nfrom copy import deepcopy\nimport coremltools as ct\nimport numpy as np",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "attention.SPLIT_SOFTMAX",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "attention.SPLIT_SOFTMAX = True\nCALIBRATION_DATA = [\n    \"image of a transparent tall glass with ice, fruits and mint, photograph, commercial, food, warm background, beautiful image, detailed\",\n    \"picture of dimly lit living room, minimalist furniture, vaulted ceiling, huge room, floor to ceiling window with an ocean view, nighttime, 3D render, high quality, detailed\",\n    \"modern office building, 8 stories tall, glass and steel, 3D render style, wide angle view, very detailed, sharp photographic image, in an office park, bright sunny day, clear blue skies, trees and landscaping\",\n    \"cute small cat sitting in a movie theater eating popcorn, watching a movie, cozy indoor lighting, detailed, digital painting, character design\",\n    \"a highly detailed matte painting of a man on a hill watching a rocket launch in the distance by studio ghibli, volumetric lighting, octane render, 4K resolution, hyperrealism, highly detailed, insanely detailed, cinematic lighting, depth of field\",\n    \"an undersea world with several of fish, rocks, detailed, realistic, photograph, amazing, beautiful, high resolution\",\n    \"large ocean wave hitting a beach at sunset, photograph, detailed\",\n    \"pocket watch on a table, close up. macro, sharp, high gloss, brass, gears, sharp, detailed\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "CALIBRATION_DATA",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "CALIBRATION_DATA = [\n    \"image of a transparent tall glass with ice, fruits and mint, photograph, commercial, food, warm background, beautiful image, detailed\",\n    \"picture of dimly lit living room, minimalist furniture, vaulted ceiling, huge room, floor to ceiling window with an ocean view, nighttime, 3D render, high quality, detailed\",\n    \"modern office building, 8 stories tall, glass and steel, 3D render style, wide angle view, very detailed, sharp photographic image, in an office park, bright sunny day, clear blue skies, trees and landscaping\",\n    \"cute small cat sitting in a movie theater eating popcorn, watching a movie, cozy indoor lighting, detailed, digital painting, character design\",\n    \"a highly detailed matte painting of a man on a hill watching a rocket launch in the distance by studio ghibli, volumetric lighting, octane render, 4K resolution, hyperrealism, highly detailed, insanely detailed, cinematic lighting, depth of field\",\n    \"an undersea world with several of fish, rocks, detailed, realistic, photograph, amazing, beautiful, high resolution\",\n    \"large ocean wave hitting a beach at sunset, photograph, detailed\",\n    \"pocket watch on a table, close up. macro, sharp, high gloss, brass, gears, sharp, detailed\",\n    \"pocket watch in the style of pablo picasso, painting\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "RANDOM_TEST_DATA",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "peekOfCode": "RANDOM_TEST_DATA = [\n    \"a black and brown dog standing outside a door.\",\n    \"a person on a motorcycle makes a turn on the track.\",\n    \"inflatable boats sit on the arizona river, and on the bank\",\n    \"a white cat sitting under a white umbrella\",\n    \"black bear standing in a field of grass under a tree.\",\n    \"a train that is parked on tracks and has graffiti writing on it, with a mountain range in the background.\",\n    \"a cake inside of a pan sitting in an oven.\",\n    \"a table with paper plates and flowers in a home\",\n]",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.activation_quantization",
        "documentation": {}
    },
    {
        "label": "softmax",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "def softmax(x, dim):\n    # Reduction max\n    max_x = x.max(dim=dim, keepdim=True).values\n    # EW sub\n    x -= max_x\n    # Scale for EXP to EXP2, Activation EXP2\n    scaled_x = x * (1 / math.log(2))\n    exp_act = torch.exp2(scaled_x)\n    # Reduction Sum + Inv\n    exp_sum_inv = 1 / exp_act.sum(dim=dim, keepdims=True)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "split_einsum",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "def split_einsum(q, k, v, mask, heads, dim_head):\n    \"\"\" Attention Implementation backing AttentionImplementations.SPLIT_EINSUM\n    - Implements https://machinelearning.apple.com/research/neural-engine-transformers\n    - Recommended for ANE\n    - Marginally slower on GPU\n    \"\"\"\n    mh_q = [\n        q[:, head_idx * dim_head:(head_idx + 1) *\n          dim_head, :, :] for head_idx in range(heads)\n    ]  # (bs, dim_head, 1, max_seq_length) * heads",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "split_einsum_v2",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "def split_einsum_v2(q, k, v, mask, heads, dim_head):\n    \"\"\" Attention Implementation backing AttentionImplementations.SPLIT_EINSUM_V2\n    - Implements https://machinelearning.apple.com/research/neural-engine-transformers\n    - Recommended for ANE\n    - Marginally slower on GPU\n    - Chunks the query sequence to avoid large intermediate tensors and improves ANE performance\n    \"\"\"\n    query_seq_length = q.size(3)\n    num_chunks = query_seq_length // CHUNK_SIZE\n    if num_chunks == 0:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "original",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "def original(q, k, v, mask, heads, dim_head):\n    \"\"\" Attention Implementation backing AttentionImplementations.ORIGINAL\n    - Not recommended for ANE\n    - Recommended for GPU\n    \"\"\"\n    bs = q.size(0)\n    mh_q = q.view(bs, heads, dim_head, -1)\n    mh_k = k.view(bs, heads, dim_head, -1)\n    mh_v = v.view(bs, heads, dim_head, -1)\n    attn_weights = torch.einsum(\"bhcq,bhck->bhqk\", [mh_q, mh_k])",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport torch\nimport math\nSPLIT_SOFTMAX = False\ndef softmax(x, dim):\n    # Reduction max\n    max_x = x.max(dim=dim, keepdim=True).values\n    # EW sub\n    x -= max_x",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "SPLIT_SOFTMAX",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "SPLIT_SOFTMAX = False\ndef softmax(x, dim):\n    # Reduction max\n    max_x = x.max(dim=dim, keepdim=True).values\n    # EW sub\n    x -= max_x\n    # Scale for EXP to EXP2, Activation EXP2\n    scaled_x = x * (1 / math.log(2))\n    exp_act = torch.exp2(scaled_x)\n    # Reduction Sum + Inv",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "CHUNK_SIZE",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "peekOfCode": "CHUNK_SIZE = 512\ndef split_einsum_v2(q, k, v, mask, heads, dim_head):\n    \"\"\" Attention Implementation backing AttentionImplementations.SPLIT_EINSUM_V2\n    - Implements https://machinelearning.apple.com/research/neural-engine-transformers\n    - Recommended for ANE\n    - Marginally slower on GPU\n    - Chunks the query sequence to avoid large intermediate tensors and improves ANE performance\n    \"\"\"\n    query_seq_length = q.size(3)\n    num_chunks = query_seq_length // CHUNK_SIZE",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.attention",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "peekOfCode": "def main(args):\n    ct_version = ct.__version__\n    if ct_version != \"8.0b2\" and ct_version < \"8.0\":\n        # With coremltools version <= 8.0b1,\n        # we use the legacy implementation.\n        # TODO: Remove the logic after setting the coremltools dependency >= 8.0.\n        logger.info(\n            f\"coremltools version {ct_version} detected. Recommended upgrading the package version to \"\n            f\"'8.0b2' when you running chunk_mlprogram.py script for the latest supports and bug fixes.\"\n        )",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport numpy as np\nimport os\nfrom python_coreml_stable_diffusion import torch2coreml\nimport shutil\nimport time\ndef _verify_output_correctness_of_chunks(full_model,\n                                         first_chunk_model=None,\n                                         second_chunk_model=None,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.chunk_mlprogram",
        "documentation": {}
    },
    {
        "label": "ControlNetConditioningEmbedding",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "peekOfCode": "class ControlNetConditioningEmbedding(nn.Module):\n    def __init__(\n        self,\n        conditioning_embedding_channels,\n        conditioning_channels=3,\n        block_out_channels=(16, 32, 96, 256),\n    ):\n        super().__init__()\n        self.conv_in = nn.Conv2d(conditioning_channels, block_out_channels[0], kernel_size=3, padding=1)\n        self.blocks = nn.ModuleList([])",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "documentation": {}
    },
    {
        "label": "ControlNetModel",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "peekOfCode": "class ControlNetModel(ModelMixin, ConfigMixin):\n    @register_to_config\n    def __init__(\n        self,\n        in_channels=4,\n        flip_sin_to_cos=True,\n        freq_shift=0,\n        down_block_types=(\n            \"CrossAttnDownBlock2D\",\n            \"CrossAttnDownBlock2D\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.controlnet",
        "documentation": {}
    },
    {
        "label": "CoreMLModel",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "peekOfCode": "class CoreMLModel:\n    \"\"\" Wrapper for running CoreML models using coremltools\n    \"\"\"\n    def __init__(self, model_path, compute_unit, sources='packages', optimization_hints=None):\n        logger.info(f\"Loading {model_path}\")\n        start = time.time()\n        if sources == 'packages':\n            assert os.path.exists(model_path) and model_path.endswith(\".mlpackage\")\n            self.model = ct.models.MLModel(\n                model_path,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "get_resource_type",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "peekOfCode": "def get_resource_type(resources_dir: str) -> str:\n    \"\"\"\n        Detect resource type based on filepath extensions.\n        returns:\n            `packages`: for .mlpackage resources\n            'compiled`: for .mlmodelc resources\n    \"\"\"\n    directories = [f for f in os.listdir(resources_dir) if os.path.isdir(os.path.join(resources_dir, f))]\n    # consider directories ending with extension\n    extensions = set([os.path.splitext(e)[1] for e in directories if os.path.splitext(e)[1]])",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "get_available_compute_units",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "peekOfCode": "def get_available_compute_units():\n    return tuple(cu for cu in ct.ComputeUnit._member_names_)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport numpy as np\nimport os\nimport time\nimport subprocess\nimport sys\ndef _macos_version():\n    \"\"\"\n    Returns macOS version as a tuple of integers. On non-Macs, returns an empty tuple.",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "LOAD_TIME_INFO_MSG_TRIGGER",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "peekOfCode": "LOAD_TIME_INFO_MSG_TRIGGER = 10  # seconds\ndef get_resource_type(resources_dir: str) -> str:\n    \"\"\"\n        Detect resource type based on filepath extensions.\n        returns:\n            `packages`: for .mlpackage resources\n            'compiled`: for .mlmodelc resources\n    \"\"\"\n    directories = [f for f in os.listdir(resources_dir) if os.path.isdir(os.path.join(resources_dir, f))]\n    # consider directories ending with extension",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.coreml_model",
        "documentation": {}
    },
    {
        "label": "LayerNormANE",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.layer_norm",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.layer_norm",
        "peekOfCode": "class LayerNormANE(nn.Module):\n    \"\"\" LayerNorm optimized for Apple Neural Engine (ANE) execution\n    Note: This layer only supports normalization over the final dim. It expects `num_channels`\n    as an argument and not `normalized_shape` which is used by `torch.nn.LayerNorm`.\n    \"\"\"\n    def __init__(self,\n                 num_channels,\n                 clip_mag=None,\n                 eps=1e-5,\n                 elementwise_affine=True):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.layer_norm",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "peekOfCode": "def main(args):\n    # Load Core ML model\n    coreml_model = ct.models.MLModel(args.mlpackage_path, compute_units=ct.ComputeUnit.CPU_ONLY)\n    logger.info(f\"Loaded {args.mlpackage_path}\")\n    # Load palettization recipe\n    with open(args.pre_analysis_json_path, 'r') as f:\n        pre_analysis = json.load(f)\n    if args.selected_recipe not in list(pre_analysis[\"recipes\"]):\n        raise KeyError(\n            f\"--selected-recipe ({args.selected_recipe}) not found in \"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\ndef main(args):\n    # Load Core ML model\n    coreml_model = ct.models.MLModel(args.mlpackage_path, compute_units=ct.ComputeUnit.CPU_ONLY)\n    logger.info(f\"Loaded {args.mlpackage_path}\")\n    # Load palettization recipe\n    with open(args.pre_analysis_json_path, 'r') as f:\n        pre_analysis = json.load(f)\n    if args.selected_recipe not in list(pre_analysis[\"recipes\"]):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_apply",
        "documentation": {}
    },
    {
        "label": "fake_linear_quantize",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def fake_linear_quantize(val, axis=-1, mode='LINEAR', dtype=types.int8):\n    from coremltools.optimize.coreml._quantization_passes import AffineQuantParams\n    from coremltools.converters.mil.mil.types.type_mapping import nptype_from_builtin\n    val_dtype = val.dtype\n    def _ensure_numerical_range_and_cast(val, low, high, np_dtype):\n        '''\n        For some cases, the computed quantized data might exceed the data range.\n        For instance, after rounding and addition, we might get `128` for the int8 quantization.\n        This utility function ensures the val in the data range before doing the cast.\n        '''",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "fake_palettize",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def fake_palettize(module, nbits, in_ngroups=1, out_ngroups=1):\n    \"\"\" Simulate weight palettization\n    \"\"\"\n    from coremltools.models.neural_network.quantization_utils import _get_kmeans_lookup_table_and_weight\n    def compress_kmeans(val, nbits):\n        lut, indices = _get_kmeans_lookup_table_and_weight(nbits, val)\n        lut = lut.astype(val.dtype)\n        indices = indices.astype(np.uint8)\n        return lut, indices\n    dtype = module.weight.data.dtype",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "restore_weight",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def restore_weight(module, value):\n    device = module.weight.data.device\n    module.weight.data = value.to(device)\ndef get_palettizable_modules(unet, min_size=PALETTIZE_MIN_SIZE):\n    ret = [\n        (name, getattr(module, 'weight').data.numel()) for name, module in unet.named_modules()\n        if isinstance(module, (nn.Linear, nn.Conv2d))\n        if hasattr(module, 'weight') and getattr(module, 'weight').data.numel() > min_size\n    ]\n    candidates, sizes = [[a for a,b in ret], [b for a,b in ret]]",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "get_palettizable_modules",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def get_palettizable_modules(unet, min_size=PALETTIZE_MIN_SIZE):\n    ret = [\n        (name, getattr(module, 'weight').data.numel()) for name, module in unet.named_modules()\n        if isinstance(module, (nn.Linear, nn.Conv2d))\n        if hasattr(module, 'weight') and getattr(module, 'weight').data.numel() > min_size\n    ]\n    candidates, sizes = [[a for a,b in ret], [b for a,b in ret]]\n    logger.info(f\"{len(candidates)} candidate tensors with {sum(sizes)/1e6} M total params\")\n    return candidates, sizes\ndef fake_int8_quantize(module):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "fake_int8_quantize",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def fake_int8_quantize(module):\n    i = 0\n    for name, submodule in tqdm(module.named_modules()):\n        if hasattr(submodule, 'weight'):\n            i+=1\n            submodule.weight.data = torch.from_numpy(\n                fake_linear_quantize(submodule.weight.data.numpy()))\n    logger.info(f\"{i} modules fake int8 quantized\")\n    return module\ndef fake_nbits_palette(module, nbits):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "fake_nbits_palette",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def fake_nbits_palette(module, nbits):\n    i = 0\n    for name, submodule in tqdm(module.named_modules()):\n        if hasattr(submodule, 'weight'):\n            i+=1\n            fake_palettize(submodule, nbits=nbits)\n    logger.info(f\"{i} modules fake {nbits}-bits palettized\")\n    return module\ndef fake_palette_from_recipe(module, recipe):\n    tot_bits = 0",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "fake_palette_from_recipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def fake_palette_from_recipe(module, recipe):\n    tot_bits = 0\n    tot_numel = 0\n    for name, submodule in tqdm(module.named_modules()):\n        if hasattr(submodule, 'weight'):\n            tot_numel += submodule.weight.numel()\n            if name in recipe:\n                nbits = recipe[name]\n                assert nbits in NBITS + [16]\n                tot_bits += submodule.weight.numel() * nbits",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "run_pipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def run_pipe(pipe):\n    if torch.backends.mps.is_available():\n        device = \"mps\"\n    elif torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    logger.debug(f\"Placing pipe in {device}\")\n    global rng, rng_state\n    rng.set_state(rng_state)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "benchmark_signal_integrity",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def benchmark_signal_integrity(pipe,\n                               candidates,\n                               nbits,\n                               cumulative,\n                               in_ngroups=1,\n                               out_ngroups=1,\n                               ref_out=None,\n                               ):\n    results = {}\n    results['metadata'] = {",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "descending_psnr_order",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def descending_psnr_order(results):\n    if 'metadata' in results:\n        results.pop('metadata')\n    return OrderedDict(sorted(results.items(), key=lambda items: -sum(items[1])))\ndef simulate_quant_fn(ref_pipe, quantization_to_simulate):\n    simulated_pipe = deepcopy(ref_pipe.to('cpu'))\n    quantization_to_simulate(simulated_pipe.unet)\n    simulated_out = run_pipe(simulated_pipe)\n    del simulated_pipe\n    gc.collect()",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "simulate_quant_fn",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def simulate_quant_fn(ref_pipe, quantization_to_simulate):\n    simulated_pipe = deepcopy(ref_pipe.to('cpu'))\n    quantization_to_simulate(simulated_pipe.unet)\n    simulated_out = run_pipe(simulated_pipe)\n    del simulated_pipe\n    gc.collect()\n    ref_out = run_pipe(ref_pipe)\n    simulated_psnr = sum([\n        float(f\"{compute_psnr(r, t):.1f}\")\n        for r, t in zip(ref_out, simulated_out)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "build_recipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def build_recipe(results, sizes, psnr_threshold, default_nbits):\n    stats = {'nbits': 0}\n    recipe = {}\n    for key in results[str(NBITS[0])]:\n        if key == 'metadata':\n            continue\n        achieved_nbits = default_nbits\n        for nbits in NBITS:\n            avg_psnr = sum(results[str(nbits)][key])/len(RANDOM_TEST_DATA)\n            if avg_psnr > psnr_threshold:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "plot",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def plot(results, args):\n    import matplotlib.pyplot as plt\n    max_model_size = sum(results['cumulative'][str(NBITS[0])]['metadata']['sizes'])\n    f, ax = plt.subplots(1, 1, figsize=(7, 5))\n    def compute_x_axis(sizes, nbits, default_nbits):\n        max_compression_percent = (default_nbits - nbits) / default_nbits\n        progress = np.cumsum(sizes)\n        normalized_progress = progress / progress.max()\n        return normalized_progress * max_compression_percent * 100\n    # Linear 8-bit baseline and the intercept points for mixed-bit recipes",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "def main(args):\n    # Initialize pipe\n    pipe = get_pipeline(args)\n    # Preserve a pristine copy for reference outputs\n    ref_pipe = deepcopy(pipe)\n    if args.default_nbits != 16:\n        logger.info(f\"Palettizing unet to default {args.default_nbits}-bit\")\n        fake_nbits_palette(pipe.unet, args.default_nbits)\n        logger.info(\"Done.\")\n    # Cache reference outputs",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "logger = logging.getLogger()\nlogger.setLevel('INFO')\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom python_coreml_stable_diffusion.torch2coreml import compute_psnr, get_pipeline\nimport time\nimport torch\nimport torch.nn as nn\nimport requests",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "NBITS",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "NBITS = [1, 2, 4, 6, 8]\n# Minimum number of elements in a weight tensor to be considered for palettization\n# (saves pre-analysis time)\nPALETTIZE_MIN_SIZE = 1e5\n# Signal integrity is computed based on these 4 random prompts\nRANDOM_TEST_DATA = [\n    \"a black and brown dog standing outside a door.\",\n    \"a person on a motorcycle makes a turn on the track.\",\n    \"inflatable boats sit on the arizona river, and on the bank\",\n    \"a white cat sitting under a white umbrella\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "PALETTIZE_MIN_SIZE",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "PALETTIZE_MIN_SIZE = 1e5\n# Signal integrity is computed based on these 4 random prompts\nRANDOM_TEST_DATA = [\n    \"a black and brown dog standing outside a door.\",\n    \"a person on a motorcycle makes a turn on the track.\",\n    \"inflatable boats sit on the arizona river, and on the bank\",\n    \"a white cat sitting under a white umbrella\",\n    \"black bear standing in a field of grass under a tree.\",\n    \"a train that is parked on tracks and has graffiti writing on it, with a mountain range in the background.\",\n    \"a cake inside of a pan sitting in an oven.\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "RANDOM_TEST_DATA",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "RANDOM_TEST_DATA = [\n    \"a black and brown dog standing outside a door.\",\n    \"a person on a motorcycle makes a turn on the track.\",\n    \"inflatable boats sit on the arizona river, and on the bank\",\n    \"a white cat sitting under a white umbrella\",\n    \"black bear standing in a field of grass under a tree.\",\n    \"a train that is parked on tracks and has graffiti writing on it, with a mountain range in the background.\",\n    \"a cake inside of a pan sitting in an oven.\",\n    \"a table with paper plates and flowers in a home\",\n]",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "TEST_RESOLUTION",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "TEST_RESOLUTION = 768\nRANDOM_TEST_IMAGE_DATA = [\n    Image.open(\n        requests.get(path, stream=True).raw).convert(\"RGB\").resize(\n            (TEST_RESOLUTION, TEST_RESOLUTION), Image.LANCZOS\n    ) for path in [\n        \"http://farm1.staticflickr.com/106/298138827_19bb723252_z.jpg\",\n        \"http://farm4.staticflickr.com/3772/9666116202_648cd752d6_z.jpg\",\n        \"http://farm3.staticflickr.com/2238/2472574092_f5534bb2f7_z.jpg\",\n        \"http://farm1.staticflickr.com/220/475442674_47d81fdc2c_z.jpg\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "RANDOM_TEST_IMAGE_DATA",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "RANDOM_TEST_IMAGE_DATA = [\n    Image.open(\n        requests.get(path, stream=True).raw).convert(\"RGB\").resize(\n            (TEST_RESOLUTION, TEST_RESOLUTION), Image.LANCZOS\n    ) for path in [\n        \"http://farm1.staticflickr.com/106/298138827_19bb723252_z.jpg\",\n        \"http://farm4.staticflickr.com/3772/9666116202_648cd752d6_z.jpg\",\n        \"http://farm3.staticflickr.com/2238/2472574092_f5534bb2f7_z.jpg\",\n        \"http://farm1.staticflickr.com/220/475442674_47d81fdc2c_z.jpg\",\n        \"http://farm8.staticflickr.com/7231/7359341784_4c5358197f_z.jpg\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "rng",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "rng = torch.Generator()\nrng_state = rng.get_state()\ndef run_pipe(pipe):\n    if torch.backends.mps.is_available():\n        device = \"mps\"\n    elif torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    logger.debug(f\"Placing pipe in {device}\")",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "rng_state",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "peekOfCode": "rng_state = rng.get_state()\ndef run_pipe(pipe):\n    if torch.backends.mps.is_available():\n        device = \"mps\"\n    elif torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    logger.debug(f\"Placing pipe in {device}\")\n    global rng, rng_state",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.mixed_bit_compression_pre_analysis",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "peekOfCode": "def main(args):\n    # Layer that was trained to map NLContextualEmbedding to your text_encoder.hidden_size dimensionality\n    text_encoder_projection = torch.jit.load(args.input_path)\n    # Prepare random inputs for tracing the network before conversion\n    random_input = torch.randn(BATCH_SIZE, MAX_SEQUENCE_LENGTH, EMBED_DIM)\n    # Create a class to bake in the reshape operations required to fit the existing model interface\n    class TextEncoderProjection(nn.Module):\n        def __init__(self, proj):\n            super().__init__()\n            self.proj = proj",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "documentation": {}
    },
    {
        "label": "MAX_SEQUENCE_LENGTH",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "peekOfCode": "MAX_SEQUENCE_LENGTH = 256\nEMBED_DIM = 512\nBATCH_SIZE = 1\ndef main(args):\n    # Layer that was trained to map NLContextualEmbedding to your text_encoder.hidden_size dimensionality\n    text_encoder_projection = torch.jit.load(args.input_path)\n    # Prepare random inputs for tracing the network before conversion\n    random_input = torch.randn(BATCH_SIZE, MAX_SEQUENCE_LENGTH, EMBED_DIM)\n    # Create a class to bake in the reshape operations required to fit the existing model interface\n    class TextEncoderProjection(nn.Module):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "documentation": {}
    },
    {
        "label": "EMBED_DIM",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "peekOfCode": "EMBED_DIM = 512\nBATCH_SIZE = 1\ndef main(args):\n    # Layer that was trained to map NLContextualEmbedding to your text_encoder.hidden_size dimensionality\n    text_encoder_projection = torch.jit.load(args.input_path)\n    # Prepare random inputs for tracing the network before conversion\n    random_input = torch.randn(BATCH_SIZE, MAX_SEQUENCE_LENGTH, EMBED_DIM)\n    # Create a class to bake in the reshape operations required to fit the existing model interface\n    class TextEncoderProjection(nn.Module):\n        def __init__(self, proj):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "peekOfCode": "BATCH_SIZE = 1\ndef main(args):\n    # Layer that was trained to map NLContextualEmbedding to your text_encoder.hidden_size dimensionality\n    text_encoder_projection = torch.jit.load(args.input_path)\n    # Prepare random inputs for tracing the network before conversion\n    random_input = torch.randn(BATCH_SIZE, MAX_SEQUENCE_LENGTH, EMBED_DIM)\n    # Create a class to bake in the reshape operations required to fit the existing model interface\n    class TextEncoderProjection(nn.Module):\n        def __init__(self, proj):\n            super().__init__()",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.multilingual_projection",
        "documentation": {}
    },
    {
        "label": "CoreMLStableDiffusionPipeline",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "class CoreMLStableDiffusionPipeline(DiffusionPipeline):\n    \"\"\" Core ML version of\n    `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline`\n    \"\"\"\n    def __init__(\n            self,\n            text_encoder: CoreMLModel,\n            unet: CoreMLModel,\n            vae_decoder: CoreMLModel,\n            scheduler: Union[",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "get_available_schedulers",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "def get_available_schedulers():\n    schedulers = {}\n    for scheduler in [DDIMScheduler,\n                      DPMSolverMultistepScheduler,\n                      EulerAncestralDiscreteScheduler,\n                      EulerDiscreteScheduler,\n                      LMSDiscreteScheduler,\n                      PNDMScheduler]:\n        schedulers[scheduler().__class__.__name__.replace(\"Scheduler\", \"\")] = scheduler\n    return schedulers",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "get_coreml_pipe",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "def get_coreml_pipe(pytorch_pipe,\n                    mlpackages_dir,\n                    model_version,\n                    compute_unit,\n                    delete_original_pipe=True,\n                    scheduler_override=None,\n                    controlnet_models=None,\n                    force_zeros_for_empty_prompt=True,\n                    sources=None):\n    \"\"\"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "get_image_path",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "def get_image_path(args, **override_kwargs):\n    \"\"\" mkdir output folder and encode metadata in the filename\n    \"\"\"\n    out_folder = os.path.join(args.o, \"_\".join(args.prompt.replace(\"/\", \"_\").rsplit(\" \")))\n    os.makedirs(out_folder, exist_ok=True)\n    out_fname = f\"randomSeed_{override_kwargs.get('seed', None) or args.seed}\"\n    out_fname += f\"_computeUnit_{override_kwargs.get('compute_unit', None) or args.compute_unit}\"\n    out_fname += f\"_modelVersion_{override_kwargs.get('model_version', None) or args.model_version.replace('/', '_')}\"\n    if args.scheduler is not None:\n        out_fname += f\"_customScheduler_{override_kwargs.get('scheduler', None) or args.scheduler}\"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "prepare_controlnet_cond",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "def prepare_controlnet_cond(image_path, height, width):\n    image = Image.open(image_path).convert(\"RGB\")\n    image = image.resize((height, width), resample=Image.LANCZOS)\n    image = np.array(image).transpose(2, 0, 1) / 255.0\n    return image\ndef main(args):\n    logger.info(f\"Setting random seed to {args.seed}\")\n    np.random.seed(args.seed)\n    logger.info(\"Initializing PyTorch pipe for reference configuration\")\n    SDP = StableDiffusionXLPipeline if 'xl' in args.model_version else StableDiffusionPipeline",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "def main(args):\n    logger.info(f\"Setting random seed to {args.seed}\")\n    np.random.seed(args.seed)\n    logger.info(\"Initializing PyTorch pipe for reference configuration\")\n    SDP = StableDiffusionXLPipeline if 'xl' in args.model_version else StableDiffusionPipeline\n    pytorch_pipe = SDP.from_pretrained(\n        args.model_version,\n        use_auth_token=True,\n    )\n    # Get Scheduler",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport numpy as np\nimport os\nfrom python_coreml_stable_diffusion.coreml_model import (\n    CoreMLModel,\n    _load_mlpackage,\n    _load_mlpackage_controlnet,\n    get_available_compute_units,\n)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "SCHEDULER_MAP",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "peekOfCode": "SCHEDULER_MAP = get_available_schedulers()\ndef get_coreml_pipe(pytorch_pipe,\n                    mlpackages_dir,\n                    model_version,\n                    compute_unit,\n                    delete_original_pipe=True,\n                    scheduler_override=None,\n                    controlnet_models=None,\n                    force_zeros_for_empty_prompt=True,\n                    sources=None):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.pipeline",
        "documentation": {}
    },
    {
        "label": "compute_psnr",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def compute_psnr(a, b):\n    \"\"\" Compute Peak-Signal-to-Noise-Ratio across two numpy.ndarray objects\n    \"\"\"\n    max_b = np.abs(b).max()\n    sumdeltasq = 0.0\n    sumdeltasq = ((a - b) * (a - b)).sum()\n    sumdeltasq /= b.size\n    sumdeltasq = np.sqrt(sumdeltasq)\n    eps = 1e-5\n    eps2 = 1e-10",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "report_correctness",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def report_correctness(original_outputs, final_outputs, log_prefix):\n    \"\"\" Report PSNR values across two compatible tensors\n    \"\"\"\n    original_psnr = compute_psnr(original_outputs, original_outputs)\n    final_psnr = compute_psnr(original_outputs, final_outputs)\n    dB_change = final_psnr - original_psnr\n    logger.info(\n        f\"{log_prefix}: PSNR changed by {dB_change:.1f} dB ({original_psnr:.1f} -> {final_psnr:.1f})\"\n    )\n    if final_psnr < ABSOLUTE_MIN_PSNR:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "quantize_weights",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def quantize_weights(args):\n    \"\"\" Quantize weights to args.quantize_nbits using a palette (look-up table)\n    \"\"\"\n    for model_name in [\"text_encoder\", \"text_encoder_2\", \"unet\", \"refiner\", \"control-unet\"]:\n        logger.info(f\"Quantizing {model_name} to {args.quantize_nbits}-bit precision\")\n        out_path = _get_out_path(args, model_name)\n        _quantize_weights(\n            out_path,\n            model_name,\n            args.quantize_nbits",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "bundle_resources_for_swift_cli",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def bundle_resources_for_swift_cli(args):\n    \"\"\"\n    - Compiles Core ML models from mlpackage into mlmodelc format\n    - Download tokenizer resources for the text encoder\n    \"\"\"\n    resources_dir = os.path.join(args.o, \"Resources\")\n    if not os.path.exists(resources_dir):\n        os.makedirs(resources_dir, exist_ok=True)\n        logger.info(f\"Created {resources_dir} for Swift CLI assets\")\n    # Compile model using coremlcompiler (Significantly reduces the load time for unet)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "patched_make_causal_mask",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def patched_make_causal_mask(input_ids_shape, dtype, device, past_key_values_length: int = 0):\n    \"\"\" Patch to replace torch.finfo(dtype).min with -1e4\n    \"\"\"\n    bsz, tgt_len = input_ids_shape\n    mask = torch.full((tgt_len, tgt_len), torch.tensor(-1e4, device=device), device=device)\n    mask_cond = torch.arange(mask.size(-1), device=device)\n    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n    mask = mask.to(dtype)\n    if past_key_values_length > 0:\n        mask = torch.cat([torch.zeros(tgt_len, past_key_values_length, dtype=dtype, device=device), mask], dim=-1)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_text_encoder",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_text_encoder(text_encoder, tokenizer, submodule_name, args):\n    \"\"\" Converts the text encoder component of Stable Diffusion\n    \"\"\"\n    text_encoder = text_encoder.to(dtype=torch.float32)\n    out_path = _get_out_path(args, submodule_name)\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`{submodule_name}` already exists at {out_path}, skipping conversion.\"\n        )\n        return",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "modify_coremltools_torch_frontend_badbmm",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def modify_coremltools_torch_frontend_badbmm():\n    \"\"\"\n    Modifies coremltools torch frontend for baddbmm to be robust to the `beta` argument being of non-float dtype:\n    e.g. https://github.com/huggingface/diffusers/blob/v0.8.1/src/diffusers/models/attention.py#L315\n    \"\"\"\n    from coremltools.converters.mil import register_torch_op\n    from coremltools.converters.mil.mil import Builder as mb\n    from coremltools.converters.mil.frontend.torch.ops import _get_inputs\n    from coremltools.converters.mil.frontend.torch.torch_op_registry import _TORCH_OPS_REGISTRY\n    if \"baddbmm\" in _TORCH_OPS_REGISTRY:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_vae_decoder",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_vae_decoder(pipe, args):\n    \"\"\" Converts the VAE Decoder component of Stable Diffusion\n    \"\"\"\n    out_path = _get_out_path(args, \"vae_decoder\")\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`vae_decoder` already exists at {out_path}, skipping conversion.\"\n        )\n        return\n    if not hasattr(pipe, \"unet\"):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_vae_decoder_sd3",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_vae_decoder_sd3(args):\n    \"\"\" Converts the VAE component of Stable Diffusion 3\n    \"\"\"\n    out_path = _get_out_path(args, \"vae_decoder\")\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`vae_decoder` already exists at {out_path}, skipping conversion.\"\n        )\n        return\n    # Convert the VAE Decoder model via DiffusionKit",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_vae_encoder",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_vae_encoder(pipe, args):\n    \"\"\" Converts the VAE Encoder component of Stable Diffusion\n    \"\"\"\n    out_path = _get_out_path(args, \"vae_encoder\")\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`vae_encoder` already exists at {out_path}, skipping conversion.\"\n        )\n        return\n    if not hasattr(pipe, \"unet\"):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_unet",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_unet(pipe, args, model_name=None):\n    \"\"\" Converts the UNet component of Stable Diffusion\n    \"\"\"\n    if args.unet_support_controlnet:\n        unet_name = \"control-unet\"\n    else:\n        unet_name = model_name or \"unet\"\n    out_path = _get_out_path(args, unet_name)\n    # Check if Unet was previously exported and then chunked\n    unet_chunks_exist = all(",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_mmdit",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_mmdit(args):\n    \"\"\" Converts the MMDiT component of Stable Diffusion 3\n    \"\"\"\n    out_path = _get_out_path(args, \"mmdit\")\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`mmdit` already exists at {out_path}, skipping conversion.\"\n        )\n        return\n    # Convert the MMDiT model via DiffusionKit",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_safety_checker",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_safety_checker(pipe, args):\n    \"\"\" Converts the Safety Checker component of Stable Diffusion\n    \"\"\"\n    if pipe.safety_checker is None:\n        logger.warning(\n            f\"diffusers pipeline for {args.model_version} does not have a `safety_checker` module! \" \\\n            \"`--convert-safety-checker` will be ignored.\"\n        )\n        return\n    out_path = _get_out_path(args, \"safety_checker\")",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "convert_controlnet",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def convert_controlnet(pipe, args):\n    \"\"\" Converts each ControlNet for Stable Diffusion\n    \"\"\"\n    if not hasattr(pipe, \"unet\"):\n        raise RuntimeError(\n            \"convert_unet() deletes pipe.unet to save RAM. \"\n            \"Please use convert_vae_encoder() before convert_unet()\")\n    if not hasattr(pipe, \"text_encoder\"):\n            raise RuntimeError(\n                \"convert_text_encoder() deletes pipe.text_encoder to save RAM. \"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "get_pipeline",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def get_pipeline(args):\n    model_version = args.model_version\n    logger.info(f\"Initializing DiffusionPipeline with {model_version}..\")\n    if args.custom_vae_version:\n        from diffusers import AutoencoderKL\n        vae = AutoencoderKL.from_pretrained(args.custom_vae_version, torch_dtype=torch.float16)\n        pipe = DiffusionPipeline.from_pretrained(model_version,\n                                            torch_dtype=torch.float16,\n                                            variant=\"fp16\",\n                                            use_safetensors=True,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def main(args):\n    os.makedirs(args.o, exist_ok=True)\n    # Instantiate diffusers pipe as reference\n    pipe = get_pipeline(args)\n    # Register the selected attention implementation globally\n    unet.ATTENTION_IMPLEMENTATION_IN_EFFECT = unet.AttentionImplementations[\n        args.attention_implementation]\n    logger.info(\n        f\"Attention implementation in effect: {unet.ATTENTION_IMPLEMENTATION_IN_EFFECT}\"\n    )",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "parser_spec",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "def parser_spec():\n    parser = argparse.ArgumentParser()\n    # Select which models to export (All are needed for text-to-image pipeline to function)\n    parser.add_argument(\"--convert-text-encoder\", action=\"store_true\")\n    parser.add_argument(\"--convert-vae-decoder\", action=\"store_true\")\n    parser.add_argument(\"--convert-vae-encoder\", action=\"store_true\")\n    parser.add_argument(\"--convert-unet\", action=\"store_true\")\n    parser.add_argument(\"--convert-mmdit\", action=\"store_true\")\n    parser.add_argument(\"--convert-safety-checker\", action=\"store_true\")\n    parser.add_argument(",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport numpy as np\nimport os\nimport requests\nimport shutil\nimport time\nimport re\nimport pathlib\nimport torch",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "ABSOLUTE_MIN_PSNR",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "ABSOLUTE_MIN_PSNR = 35\ndef report_correctness(original_outputs, final_outputs, log_prefix):\n    \"\"\" Report PSNR values across two compatible tensors\n    \"\"\"\n    original_psnr = compute_psnr(original_outputs, original_outputs)\n    final_psnr = compute_psnr(original_outputs, final_outputs)\n    dB_change = final_psnr - original_psnr\n    logger.info(\n        f\"{log_prefix}: PSNR changed by {dB_change:.1f} dB ({original_psnr:.1f} -> {final_psnr:.1f})\"\n    )",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "modeling_clip._make_causal_mask",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "modeling_clip._make_causal_mask = patched_make_causal_mask # For transformers >= 4.30.0 and transformers < 4.35.0\nmodeling_clip._create_4d_causal_attention_mask = patched_make_causal_mask # For transformers >= 4.35.0\ndef convert_text_encoder(text_encoder, tokenizer, submodule_name, args):\n    \"\"\" Converts the text encoder component of Stable Diffusion\n    \"\"\"\n    text_encoder = text_encoder.to(dtype=torch.float32)\n    out_path = _get_out_path(args, submodule_name)\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`{submodule_name}` already exists at {out_path}, skipping conversion.\"",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "modeling_clip._create_4d_causal_attention_mask",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "peekOfCode": "modeling_clip._create_4d_causal_attention_mask = patched_make_causal_mask # For transformers >= 4.35.0\ndef convert_text_encoder(text_encoder, tokenizer, submodule_name, args):\n    \"\"\" Converts the text encoder component of Stable Diffusion\n    \"\"\"\n    text_encoder = text_encoder.to(dtype=torch.float32)\n    out_path = _get_out_path(args, submodule_name)\n    if os.path.exists(out_path):\n        logger.info(\n            f\"`{submodule_name}` already exists at {out_path}, skipping conversion.\"\n        )",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.torch2coreml",
        "documentation": {}
    },
    {
        "label": "AttentionImplementations",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class AttentionImplementations(Enum):\n    ORIGINAL = \"ORIGINAL\"\n    SPLIT_EINSUM = \"SPLIT_EINSUM\"\n    SPLIT_EINSUM_V2 = \"SPLIT_EINSUM_V2\"\nATTENTION_IMPLEMENTATION_IN_EFFECT = AttentionImplementations.SPLIT_EINSUM\nWARN_MSG = \\\n    \"This `nn.Module` is intended for Apple Silicon deployment only. \" \\\n    \"PyTorch-specific optimizations and training is disabled\"\nclass Einsum(nn.Module):\n    def __init__(self, heads, dim_head):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "Einsum",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class Einsum(nn.Module):\n    def __init__(self, heads, dim_head):\n        super().__init__()\n        self.heads = heads\n        self.dim_head = dim_head\n    def forward(self, q, k, v, mask):\n        if ATTENTION_IMPLEMENTATION_IN_EFFECT == AttentionImplementations.ORIGINAL:\n            return attention.original(q, k, v, mask, self.heads, self.dim_head)\n        elif ATTENTION_IMPLEMENTATION_IN_EFFECT == AttentionImplementations.SPLIT_EINSUM:\n            return attention.split_einsum(q, k, v, mask, self.heads, self.dim_head)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "CrossAttention",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class CrossAttention(nn.Module):\n    \"\"\" Apple Silicon friendly version of `diffusers.models.attention.CrossAttention`\n    \"\"\"\n    def __init__(self, query_dim, context_dim=None, heads=8, dim_head=64):\n        super().__init__()\n        inner_dim = dim_head * heads\n        context_dim = context_dim if context_dim is not None else query_dim\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        self.dim_head = dim_head",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "LayerNormANE",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class LayerNormANE(LayerNormANE):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._register_load_state_dict_pre_hook(\n            correct_for_bias_scale_order_inversion)\n# Reference: https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/unet_2d_condition.py\n# (modified, e.g. the attention implementation)\nclass CrossAttnUpBlock2D(nn.Module):\n    def __init__(\n        self,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "CrossAttnUpBlock2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class CrossAttnUpBlock2D(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        prev_output_channel,\n        temb_channels,\n        num_layers=1,\n        resnet_eps=1e-6,\n        resnet_time_scale_shift=\"default\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "UpBlock2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class UpBlock2D(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        prev_output_channel,\n        out_channels,\n        temb_channels,\n        num_layers=1,\n        resnet_eps=1e-6,\n        resnet_time_scale_shift=\"default\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "CrossAttnDownBlock2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class CrossAttnDownBlock2D(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        temb_channels,\n        transformer_layers_per_block=1,\n        num_layers=1,\n        resnet_eps=1e-6,\n        resnet_time_scale_shift=\"default\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "DownBlock2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class DownBlock2D(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        temb_channels,\n        num_layers=1,\n        resnet_eps=1e-6,\n        resnet_time_scale_shift=\"default\",\n        resnet_act_fn=\"swish\",",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "ResnetBlock2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class ResnetBlock2D(nn.Module):\n    def __init__(\n        self,\n        *,\n        in_channels,\n        out_channels=None,\n        conv_shortcut=False,\n        temb_channels=512,\n        groups=32,\n        groups_out=None,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "Upsample2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class Upsample2D(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv = nn.Conv2d(channels, channels, 3, padding=1)\n    def forward(self, x):\n        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n        return self.conv(x)\nclass Downsample2D(nn.Module):\n    def __init__(self, channels):\n        super().__init__()",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "Downsample2D",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class Downsample2D(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv = nn.Conv2d(channels, channels, 3, stride=2, padding=1)\n    def forward(self, x):\n        return self.conv(x)\nclass SpatialTransformer(nn.Module):\n    def __init__(\n        self,\n        in_channels,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "SpatialTransformer",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class SpatialTransformer(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        n_heads,\n        d_head,\n        depth=1,\n        context_dim=None,\n    ):\n        super().__init__()",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "BasicTransformerBlock",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class BasicTransformerBlock(nn.Module):\n    def __init__(self, dim, n_heads, d_head, context_dim=None, gated_ff=True):\n        super().__init__()\n        self.attn1 = CrossAttention(\n            query_dim=dim,\n            heads=n_heads,\n            dim_head=d_head,\n        )\n        self.ff = FeedForward(dim, glu=gated_ff)\n        self.attn2 = CrossAttention(",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "FeedForward",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class FeedForward(nn.Module):\n    def __init__(self, dim, dim_out=None, mult=4, glu=False):\n        super().__init__()\n        inner_dim = int(dim * mult)\n        self.net = nn.Sequential(\n            GEGLU(dim_in=dim, dim_out=inner_dim), nn.Identity(),\n            nn.Conv2d(inner_dim,\n                      dim_out if dim_out is not None else dim,\n                      kernel_size=1))\n    def forward(self, hidden_states):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "GEGLU",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class GEGLU(nn.Module):\n    def __init__(self, dim_in, dim_out):\n        super().__init__()\n        self.proj = nn.Conv2d(dim_in, dim_out * 2, kernel_size=1)\n    def forward(self, hidden_states):\n        hidden_states, gate = self.proj(hidden_states).chunk(2, dim=1)\n        return hidden_states * F.gelu(gate)\ndef get_activation(act_fn):\n    if act_fn in [\"swish\", \"silu\"]:\n        return nn.SiLU()",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "TimestepEmbedding",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class TimestepEmbedding(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        time_embed_dim,\n        act_fn = \"silu\",\n        out_dim = None,\n        post_act_fn = None,\n        cond_proj_dim=None,\n    ):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "Timesteps",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class Timesteps(nn.Module):\n    def __init__(self, num_channels, flip_sin_to_cos, downscale_freq_shift):\n        super().__init__()\n        self.num_channels = num_channels\n        self.flip_sin_to_cos = flip_sin_to_cos\n        self.downscale_freq_shift = downscale_freq_shift\n    def forward(self, timesteps):\n        t_emb = get_timestep_embedding(\n            timesteps,\n            self.num_channels,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "UNetMidBlock2DCrossAttn",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class UNetMidBlock2DCrossAttn(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        temb_channels,\n        num_layers=1,\n        resnet_eps=1e-6,\n        resnet_time_scale_shift=\"default\",\n        resnet_act_fn=\"swish\",\n        resnet_groups=32,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "UNet2DConditionModel",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class UNet2DConditionModel(ModelMixin, ConfigMixin):\n    @register_to_config\n    def __init__(\n        self,\n        sample_size=None,\n        in_channels=4,\n        out_channels=4,\n        center_input_sample=False,\n        flip_sin_to_cos=True,\n        freq_shift=0,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "UNet2DConditionModelXL",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "class UNet2DConditionModelXL(UNet2DConditionModel):\n    \"\"\" UNet2DConditionModel variant for Stable Diffusion XL\n    with an extended forward() signature\n    \"\"\"\n    def forward(\n        self,\n        sample,\n        timestep,\n        encoder_hidden_states,\n        time_ids,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "linear_to_conv2d_map",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def linear_to_conv2d_map(state_dict, prefix, local_metadata, strict,\n                         missing_keys, unexpected_keys, error_msgs):\n    \"\"\" Unsqueeze twice to map nn.Linear weights to nn.Conv2d weights\n    \"\"\"\n    for k in state_dict:\n        if 'weight' in k and len(state_dict[k].shape) == 2:\n            state_dict[k] = state_dict[k][:, :, None, None]\n# Note: torch.nn.LayerNorm and ane_transformers.reference.layer_norm.LayerNormANE\n# apply scale and bias terms in opposite orders. In order to accurately restore a\n# state_dict trained using the former into the the latter, we adjust the bias term",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "correct_for_bias_scale_order_inversion",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def correct_for_bias_scale_order_inversion(state_dict, prefix, local_metadata,\n                                           strict, missing_keys,\n                                           unexpected_keys, error_msgs):\n    state_dict[prefix +\n               \"bias\"] = state_dict[prefix + \"bias\"] / state_dict[prefix +\n                                                                  \"weight\"]\n    return state_dict\nclass LayerNormANE(LayerNormANE):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "get_activation",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def get_activation(act_fn):\n    if act_fn in [\"swish\", \"silu\"]:\n        return nn.SiLU()\n    elif act_fn == \"mish\":\n        return nn.Mish()\n    elif act_fn == \"gelu\":\n        return nn.GELU()\n    else:\n        raise ValueError(f\"Unsupported activation function: {act_fn}\")\nclass TimestepEmbedding(nn.Module):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "get_timestep_embedding",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def get_timestep_embedding(\n    timesteps,\n    embedding_dim,\n    flip_sin_to_cos=False,\n    downscale_freq_shift=1,\n    scale=1,\n    max_period=10000,\n):\n    assert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"\n    half_dim = embedding_dim // 2",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "get_down_block",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def get_down_block(\n    down_block_type,\n    num_layers,\n    in_channels,\n    out_channels,\n    temb_channels,\n    resnet_eps,\n    resnet_act_fn,\n    attn_num_head_channels,\n    transformer_layers_per_block=1,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "get_up_block",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def get_up_block(\n    up_block_type,\n    num_layers,\n    in_channels,\n    out_channels,\n    prev_output_channel,\n    temb_channels,\n    add_upsample,\n    resnet_eps,\n    resnet_act_fn,",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "calculate_conv2d_output_shape",
        "kind": 2,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "def calculate_conv2d_output_shape(in_h, in_w, conv2d_layer):\n    k_h, k_w = conv2d_layer.kernel_size\n    pad_h, pad_w = conv2d_layer.padding\n    stride_h, stride_w = conv2d_layer.stride\n    out_h = math.floor((in_h + 2 * pad_h - k_h) / stride_h + 1)\n    out_w = math.floor((in_w + 2 * pad_w - k_w) / stride_w + 1)\n    return out_h, out_w",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# Ensure minimum macOS version requirement is met for this particular model\nfrom coremltools.models.utils import _macos_version\nif not _macos_version() >= (13, 1):\n    logger.warning(",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "ATTENTION_IMPLEMENTATION_IN_EFFECT",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "ATTENTION_IMPLEMENTATION_IN_EFFECT = AttentionImplementations.SPLIT_EINSUM\nWARN_MSG = \\\n    \"This `nn.Module` is intended for Apple Silicon deployment only. \" \\\n    \"PyTorch-specific optimizations and training is disabled\"\nclass Einsum(nn.Module):\n    def __init__(self, heads, dim_head):\n        super().__init__()\n        self.heads = heads\n        self.dim_head = dim_head\n    def forward(self, q, k, v, mask):",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "WARN_MSG",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "description": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "peekOfCode": "WARN_MSG = \\\n    \"This `nn.Module` is intended for Apple Silicon deployment only. \" \\\n    \"PyTorch-specific optimizations and training is disabled\"\nclass Einsum(nn.Module):\n    def __init__(self, heads, dim_head):\n        super().__init__()\n        self.heads = heads\n        self.dim_head = dim_head\n    def forward(self, q, k, v, mask):\n        if ATTENTION_IMPLEMENTATION_IN_EFFECT == AttentionImplementations.ORIGINAL:",
        "detail": "ios.ml-stable-diffusion.python_coreml_stable_diffusion.unet",
        "documentation": {}
    },
    {
        "label": "TestStableDiffusionForTextToImage",
        "kind": 6,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "class TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`\n    - Efficacy of the safety_checker\n    - Affinity of the generated image with the original prompt via CLIP score\n    - The bridge between Python and Swift CLI\n    - The signal parity of Swift CLI generated image with that of Python CLI\n    \"\"\"",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(\"INFO\")\n# Testing configuration\nTEST_SEED = 93\nTEST_PROMPT = \"a high quality photo of an astronaut riding a horse in space\"\nTEST_COMPUTE_UNIT = [\"CPU_AND_GPU\", \"ALL\", \"CPU_AND_NE\"]\nTEST_PSNR_THRESHOLD = 35  # dB\nTEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_SEED",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_SEED = 93\nTEST_PROMPT = \"a high quality photo of an astronaut riding a horse in space\"\nTEST_COMPUTE_UNIT = [\"CPU_AND_GPU\", \"ALL\", \"CPU_AND_NE\"]\nTEST_PSNR_THRESHOLD = 35  # dB\nTEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_PROMPT",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_PROMPT = \"a high quality photo of an astronaut riding a horse in space\"\nTEST_COMPUTE_UNIT = [\"CPU_AND_GPU\", \"ALL\", \"CPU_AND_NE\"]\nTEST_PSNR_THRESHOLD = 35  # dB\nTEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_COMPUTE_UNIT",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_COMPUTE_UNIT = [\"CPU_AND_GPU\", \"ALL\", \"CPU_AND_NE\"]\nTEST_PSNR_THRESHOLD = 35  # dB\nTEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_PSNR_THRESHOLD",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_PSNR_THRESHOLD = 35  # dB\nTEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_ABSOLUTE_MAX_LATENCY",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_ABSOLUTE_MAX_LATENCY = 90  # seconds\nTEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`\n    - Efficacy of the safety_checker",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_WARMUP_INFERENCE_STEPS",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_WARMUP_INFERENCE_STEPS = 3\nTEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`\n    - Efficacy of the safety_checker\n    - Affinity of the generated image with the original prompt via CLIP score",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_TEXT_TO_IMAGE_SPEED_REPEATS",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_TEXT_TO_IMAGE_SPEED_REPEATS = 3\nTEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`\n    - Efficacy of the safety_checker\n    - Affinity of the generated image with the original prompt via CLIP score\n    - The bridge between Python and Swift CLI",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "TEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY",
        "kind": 5,
        "importPath": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "description": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "peekOfCode": "TEST_MINIMUM_PROMPT_TO_IMAGE_CLIP_COSINE_SIMILARITY = 0.3  # in range [0.,1.]\nclass TestStableDiffusionForTextToImage(unittest.TestCase):\n    \"\"\" Test Stable Diffusion text-to-image pipeline for:\n    - PyTorch to CoreML conversion via coremltools\n    - Speed of CoreML runtime across several compute units\n    - Integration with `diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.py`\n    - Efficacy of the safety_checker\n    - Affinity of the generated image with the original prompt via CLIP score\n    - The bridge between Python and Swift CLI\n    - The signal parity of Swift CLI generated image with that of Python CLI",
        "detail": "ios.ml-stable-diffusion.tests.test_stable_diffusion",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    }
]